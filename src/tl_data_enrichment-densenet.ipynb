{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d2857016",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torchvision.models as models\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "import warnings\n",
    "import contextlib\n",
    "from datetime import datetime\n",
    "import torch.multiprocessing as mp\n",
    "import sys\n",
    "mp.set_start_method('spawn')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "54ec7dc7-0b89-4c31-a860-9fed0d121334",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.datasets import *\n",
    "from utils.eval import *\n",
    "from utils.model import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d0cb4a97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "model_names = [\n",
    "    \"resnet50\",\n",
    "    \"resnet18\", \"alexnet\", \"vgg16\",\n",
    "    \"densenet\", \"inception\", \"googlenet\", \n",
    "    \"resnext50_32x4d\", \"wide_resnet50_2\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "38922992",
   "metadata": {},
   "outputs": [],
   "source": [
    "# freezed model\n",
    "def get_original_model(net):\n",
    "    if net == \"resnet50\":\n",
    "        model = models.resnet50(weights=models.ResNet50_Weights.DEFAULT)\n",
    "        # models.resnet18(pretrained=True)\n",
    "    elif net == \"resnet18\":\n",
    "        model = models.resnet18(weights=models.ResNet18_Weights.DEFAULT)\n",
    "        # model = models.resnet18(pretrained=True)\n",
    "    elif net == \"alexnet\":\n",
    "        # model = models.alexnet(pretrained=True)\n",
    "        model = models.alexnet(weights=models.AlexNet_Weights.DEFAULT)\n",
    "    elif net == \"vgg16\":\n",
    "        model = models.vgg16(weights=models.VGG16_Weights.DEFAULT)\n",
    "        # model = models.vgg16(pretrained=True)\n",
    "    elif net == \"densenet\":\n",
    "        model = models.densenet161(weights=models.DenseNet161_Weights.DEFAULT)\n",
    "        # model = models.densenet161(pretrained=True)\n",
    "    elif net == \"inception\":\n",
    "        model = models.inception_v3(weights=models.Inception_V3_Weights.DEFAULT)\n",
    "        # model = models.inception_v3(pretrained=True)\n",
    "    elif net == \"googlenet\":\n",
    "        model = models.googlenet(weights=models.GoogLeNet_Weights.DEFAULT)\n",
    "        # model = models.googlenet(pretrained=True)\n",
    "    elif net == \"resnext50_32x4d\":\n",
    "        model = models.resnext50_32x4d(weights=models.ResNeXt50_32X4D_Weights.DEFAULT)\n",
    "        # model = models.resnext50_32x4d(pretrained=True)\n",
    "    elif net == \"wide_resnet50_2\":\n",
    "        model = models.wide_resnet50_2(weights=models.Wide_ResNet50_2_Weights.DEFAULT)\n",
    "        # model = models.wide_resnet50_2(pretrained=True)\n",
    "    else:\n",
    "        raise ValueError(\"Invalid model name\")\n",
    "    for param in model.parameters():\n",
    "        param.requires_grad = False\n",
    "    # Remove the last fully connected layer\n",
    "    if \"inception\" in net:\n",
    "        model.aux_logits=False\n",
    "        num_ftrs = model.fc.in_features\n",
    "        model.fc = nn.Identity()\n",
    "        model.fc = nn.Linear(2048, num_classes)\n",
    "        model.fc.requires_grad = True\n",
    "        optimizer = optim.SGD(model.fc.parameters(), lr=0.001, momentum=0.9)\n",
    "    if \"alexnet\" in net or \"vgg\" in net or  \"mobilenet_v3_large\" in net:\n",
    "        last_fc_layer = model.classifier[-1]\n",
    "        num_ftrs = last_fc_layer.in_features\n",
    "        model.classifier[-1] = nn.Linear(num_ftrs, num_classes)\n",
    "        model.classifier[-1].requires_grad = True\n",
    "        optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
    "    elif \"densenet\" in net:\n",
    "        last_fc_layer = model.classifier\n",
    "        num_ftrs = last_fc_layer.in_features\n",
    "        model.classifier = nn.Linear(num_ftrs, num_classes)\n",
    "        model.classifier.requires_grad = True\n",
    "        optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
    "    else:\n",
    "        num_ftrs = model.fc.in_features\n",
    "        model.fc = nn.Identity()\n",
    "        model.fc.requires_grad = True\n",
    "        model.fc = nn.Linear(num_ftrs, num_classes)\n",
    "        optimizer = optim.SGD(model.fc.parameters(), lr=0.001, momentum=0.9)\n",
    "    model = model.to(device)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    \n",
    "    return model,criterion, optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "745f0217",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 50\n",
    "def train_net(net):\n",
    "    model, criterion, optimizer = get_original_model(net)\n",
    "    original_stderr = sys.stderr\n",
    "    accuracy_list = []\n",
    "    precision_list = []\n",
    "    recall_list = []\n",
    "    confusion_matrix_list = []\n",
    "    f1_list = []\n",
    "    tps, tns, fps, fns = [], [], [], []\n",
    "    current_date = datetime.now().strftime('%Y-%m-%d')\n",
    "    save_dir = os.path.join(\"saved_models/tl+rotation\", current_date)\n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "    test_ratio=0.3\n",
    "    \n",
    "    sys.stderr = open(os.devnull, 'w')\n",
    "    \n",
    "    for timestamp in range(1, 290):\n",
    "    # for timestamp in [150, 160, 170]:\n",
    "        debug = True\n",
    "        if timestamp in  [1, 20, 40, 60, 80, 100, 120, 140, 160, 180, 200, 220, 240, 260, 280, 289]:\n",
    "            debug = True\n",
    "        if debug:\n",
    "            print(\"timestamp: \", timestamp)\n",
    "        if \"inception\" in net:\n",
    "            dataloaders = get_dataloaders(timestamp, test_ratio=test_ratio, inception=True, data_enrich=True)\n",
    "        else:\n",
    "            dataloaders = get_dataloaders(timestamp, test_ratio=test_ratio, data_enrich=True)\n",
    "        model_trained, loss_values = train_model(model, criterion, optimizer, dataloaders, num_epochs=num_epochs, inception=(\"inception\" in net), output=debug, debug=False)\n",
    "        model_filename = os.path.join(save_dir, f\"model_{net}_time_{timestamp}_epochs{num_epochs}.pt\")\n",
    "        torch.save(model_trained.state_dict(), model_filename)\n",
    "    \n",
    "        accuracy, precision, recall, f1, tp, tn, fp, fn, confusion_matrix = get_metrics(model_trained, dataloaders['test'], inception=(\"inception\" in net))\n",
    "        accuracy_list.append(accuracy)\n",
    "        precision_list.append(precision)\n",
    "        if debug:\n",
    "            print(\"Accuracy: \", accuracy)\n",
    "        recall_list.append(recall)\n",
    "        f1_list.append(f1)\n",
    "        tps.append(tp)\n",
    "        tns.append(tn)\n",
    "        fps.append(fp)\n",
    "        fns.append(fn)\n",
    "        confusion_matrix_list.append(confusion_matrix)\n",
    "    sys.stderr = original_stderr\n",
    "    return accuracy_list, precision_list, recall_list, f1_list, tps, tns, fps, fns, confusion_matrix_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fd0c11a6-b5b9-4282-bdae-a3e155acaf86",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_dicts(dict1, dict2):\n",
    "    result_dict = {}\n",
    "    for key in dict1.keys():\n",
    "        result_dict[key] = dict1[key] + dict2[key]\n",
    "    return result_dict\n",
    "    \n",
    "def write_result(model_name, accuracy_list, precision_list, recall_list, f1_list, tps, tns, fps, fns, confusion_matrix_list):\n",
    "    avg_acc = sum(accuracy_list) / len(accuracy_list)\n",
    "    avg_pre = sum(precision_list) / len(precision_list)\n",
    "    avg_rec = sum(recall_list) / len(recall_list)\n",
    "    avg_f1 = sum(f1_list) / len(f1_list)\n",
    "    output_folder = f\"./output/tl+rotation/{current_date}/{model_name}\"\n",
    "    output_file = f\"metrics_{model_name}.txt\"\n",
    "    class_labels = [\"BMP4\", \"CHIR\", \"DS\", \"DS+CHIR\",  \"WT\"]\n",
    "\n",
    "    \n",
    "    with open(os.path.join(output_folder, output_file), \"w\") as f:\n",
    "        f.write(\"Average Accuracy: \" + str(avg_acc) + \"\\n\")\n",
    "        f.write(\"Average Precision: \" + str(avg_pre) + \"\\n\")\n",
    "        f.write(\"Average Recall: \" + str(avg_rec) + \"\\n\")\n",
    "        f.write(\"Average F1 Score: \" + str(avg_f1) + \"\\n\")\n",
    "        f.write(\"Accuracy: \" + str(accuracy_list) + \"\\n\")\n",
    "        f.write(\"Precision: \" + str(precision_list) + \"\\n\")\n",
    "        f.write(\"Recall: \" + str(recall_list) + \"\\n\")\n",
    "        f.write(\"F1 Score: \" + str(f1_list) + \"\\n\")\n",
    "        f.write(\"TPs: \" + str(tps) + \"\\n\")\n",
    "        f.write(\"TNs: \" + str(tns) + \"\\n\")\n",
    "        f.write(\"FPs: \" + str(fps) + \"\\n\")\n",
    "        f.write(\"FNs: \" + str(fns) + \"\\n\")\n",
    "\n",
    "        # Write misclassified pairs\n",
    "        f.write(\"Misclassified Pairs:\\n\")\n",
    "        mis_total_map = {}\n",
    "        \n",
    "        for m in range(len(fps)):\n",
    "          \n",
    "            mis_map = {}\n",
    "            if m+1 in [1, 40, 80, 120, 160, 200, 240, 280, 289]:\n",
    "                f.write(f\"Misclassified Pairs for time {m+1}: \")\n",
    "            for i in range(len(class_labels)):\n",
    "                for j in range(i+1, len(class_labels)):\n",
    "                    pair = f\"{class_labels[i]} vs. {class_labels[j]}\"\n",
    "                    if pair not in mis_total_map:\n",
    "                        mis_total_map[pair] = 0\n",
    "                    if pair not in mis_map:\n",
    "                        mis_map[pair] = 0\n",
    "                    mis_map[f\"{class_labels[i]} vs. {class_labels[j]}\"] += confusion_matrix_list[m][i][j] + confusion_matrix_list[m][j][i]\n",
    "                    mis_total_map[f\"{class_labels[i]} vs. {class_labels[j]}\"] += confusion_matrix_list[m][i][j] + confusion_matrix_list[m][j][i]\n",
    "            if m+1 in [1, 40, 80, 120, 160, 200, 240, 280, 289]:\n",
    "                for key, val in mis_map.items():\n",
    "                    f.write(f\"{key}: {val} \")  \n",
    "                f.write(\"\\n\")\n",
    "        # for key, val in mis_total_map.items():\n",
    "        f.write(str(mis_total_map) + \"\\n\")\n",
    "    return mis_total_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f59250d2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training densenet...\n",
      "timestamp:  1\n",
      "Training complete in 1m 55s\n",
      "Best val Acc: 0.914894\n",
      "Best val loss: 0.306608\n",
      "Accuracy:  0.8723404255319149\n",
      "timestamp:  2\n",
      "Training complete in 2m 11s\n",
      "Best val Acc: 0.957447\n",
      "Best val loss: 0.264540\n",
      "Accuracy:  0.8085106382978723\n",
      "timestamp:  3\n",
      "Training complete in 2m 9s\n",
      "Best val Acc: 0.957447\n",
      "Best val loss: 0.183536\n",
      "Accuracy:  0.8723404255319149\n",
      "timestamp:  4\n",
      "Training complete in 2m 16s\n",
      "Best val Acc: 1.000000\n",
      "Best val loss: 0.104604\n",
      "Accuracy:  0.9148936170212766\n",
      "timestamp:  5\n",
      "Training complete in 2m 5s\n",
      "Best val Acc: 0.978723\n",
      "Best val loss: 0.105385\n",
      "Accuracy:  0.8723404255319149\n",
      "timestamp:  6\n",
      "Training complete in 2m 7s\n",
      "Best val Acc: 0.978723\n",
      "Best val loss: 0.109638\n",
      "Accuracy:  0.8085106382978723\n",
      "timestamp:  7\n",
      "Training complete in 1m 59s\n",
      "Best val Acc: 0.957447\n",
      "Best val loss: 0.168518\n",
      "Accuracy:  0.8723404255319149\n",
      "timestamp:  8\n",
      "Training complete in 2m 10s\n",
      "Best val Acc: 1.000000\n",
      "Best val loss: 0.106052\n",
      "Accuracy:  0.7659574468085106\n",
      "timestamp:  9\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 29\u001b[0m\n\u001b[1;32m     27\u001b[0m os\u001b[38;5;241m.\u001b[39mmakedirs(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m./output/tl+rotation/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcurrent_date\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, exist_ok\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m     28\u001b[0m show_ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m---> 29\u001b[0m accuracy_list, precision_list, recall_list, f1_list, tps, tns, fps, fns, confusion_matrix_list \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_net\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     30\u001b[0m plot_metric(accuracy_list, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m, model\u001b[38;5;241m=\u001b[39mmodel_name, save\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, show\u001b[38;5;241m=\u001b[39mshow_, output\u001b[38;5;241m=\u001b[39m\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moutput/tl+rotation/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcurrent_date\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, num_epochs\u001b[38;5;241m=\u001b[39mnum_epochs, test_ratio\u001b[38;5;241m=\u001b[39mtest_ratio)\n\u001b[1;32m     31\u001b[0m plot_metric(precision_list, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPrecision\u001b[39m\u001b[38;5;124m'\u001b[39m, model\u001b[38;5;241m=\u001b[39mmodel_name, save\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, show\u001b[38;5;241m=\u001b[39mshow_,output\u001b[38;5;241m=\u001b[39m\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moutput/tl+rotation/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcurrent_date\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, num_epochs\u001b[38;5;241m=\u001b[39mnum_epochs, test_ratio\u001b[38;5;241m=\u001b[39mtest_ratio)\n",
      "Cell \u001b[0;32mIn[5], line 29\u001b[0m, in \u001b[0;36mtrain_net\u001b[0;34m(net)\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     28\u001b[0m     dataloaders \u001b[38;5;241m=\u001b[39m get_dataloaders(timestamp, test_ratio\u001b[38;5;241m=\u001b[39mtest_ratio, data_enrich\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m---> 29\u001b[0m model_trained, loss_values \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdataloaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_epochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minception\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43minception\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mnet\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdebug\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdebug\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m     30\u001b[0m model_filename \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(save_dir, \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnet\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_time_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtimestamp\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_epochs\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_epochs\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.pt\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     31\u001b[0m torch\u001b[38;5;241m.\u001b[39msave(model_trained\u001b[38;5;241m.\u001b[39mstate_dict(), model_filename)\n",
      "File \u001b[0;32m~/projects/thesis/stem_cell_dl/src/utils/model.py:42\u001b[0m, in \u001b[0;36mtrain_model\u001b[0;34m(model, criterion, optimizer, dataloaders, num_epochs, inception, debug, output)\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[38;5;66;03m# forward\u001b[39;00m\n\u001b[1;32m     40\u001b[0m \u001b[38;5;66;03m# track history if only in train\u001b[39;00m\n\u001b[1;32m     41\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mset_grad_enabled(phase \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[0;32m---> 42\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     43\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m inception:\n\u001b[1;32m     44\u001b[0m         _, preds \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mmax(outputs, \u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[0;32m~/miniforge3/envs/myBase/lib/python3.8/site-packages/torch/nn/modules/module.py:1131\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1127\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1129\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1130\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1131\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1132\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1133\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/miniforge3/envs/myBase/lib/python3.8/site-packages/torchvision/models/densenet.py:214\u001b[0m, in \u001b[0;36mDenseNet.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    213\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 214\u001b[0m     features \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfeatures\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    215\u001b[0m     out \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mrelu(features, inplace\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m    216\u001b[0m     out \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39madaptive_avg_pool2d(out, (\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m))\n",
      "File \u001b[0;32m~/miniforge3/envs/myBase/lib/python3.8/site-packages/torch/nn/modules/module.py:1131\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1127\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1129\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1130\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1131\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1132\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1133\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/miniforge3/envs/myBase/lib/python3.8/site-packages/torch/nn/modules/container.py:139\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    137\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[1;32m    138\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[0;32m--> 139\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    140\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[0;32m~/miniforge3/envs/myBase/lib/python3.8/site-packages/torch/nn/modules/module.py:1131\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1127\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1129\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1130\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1131\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1132\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1133\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/miniforge3/envs/myBase/lib/python3.8/site-packages/torchvision/models/densenet.py:123\u001b[0m, in \u001b[0;36m_DenseBlock.forward\u001b[0;34m(self, init_features)\u001b[0m\n\u001b[1;32m    121\u001b[0m features \u001b[38;5;241m=\u001b[39m [init_features]\n\u001b[1;32m    122\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m name, layer \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mitems():\n\u001b[0;32m--> 123\u001b[0m     new_features \u001b[38;5;241m=\u001b[39m \u001b[43mlayer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfeatures\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    124\u001b[0m     features\u001b[38;5;241m.\u001b[39mappend(new_features)\n\u001b[1;32m    125\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mcat(features, \u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[0;32m~/miniforge3/envs/myBase/lib/python3.8/site-packages/torch/nn/modules/module.py:1131\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1127\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1129\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1130\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1131\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1132\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1133\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/miniforge3/envs/myBase/lib/python3.8/site-packages/torchvision/models/densenet.py:89\u001b[0m, in \u001b[0;36m_DenseLayer.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     87\u001b[0m     bottleneck_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcall_checkpoint_bottleneck(prev_features)\n\u001b[1;32m     88\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 89\u001b[0m     bottleneck_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbn_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprev_features\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     91\u001b[0m new_features \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconv2(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrelu2(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnorm2(bottleneck_output)))\n\u001b[1;32m     92\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdrop_rate \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[0;32m~/miniforge3/envs/myBase/lib/python3.8/site-packages/torchvision/models/densenet.py:50\u001b[0m, in \u001b[0;36m_DenseLayer.bn_function\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mbn_function\u001b[39m(\u001b[38;5;28mself\u001b[39m, inputs: List[Tensor]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m     49\u001b[0m     concated_features \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat(inputs, \u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m---> 50\u001b[0m     bottleneck_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv1\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrelu1\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnorm1\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconcated_features\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# noqa: T484\u001b[39;00m\n\u001b[1;32m     51\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m bottleneck_output\n",
      "File \u001b[0;32m~/miniforge3/envs/myBase/lib/python3.8/site-packages/torch/nn/modules/module.py:1131\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1127\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1129\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1130\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1131\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1132\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1133\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/miniforge3/envs/myBase/lib/python3.8/site-packages/torch/nn/modules/conv.py:459\u001b[0m, in \u001b[0;36mConv2d.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    458\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 459\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_conv_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniforge3/envs/myBase/lib/python3.8/site-packages/torch/nn/modules/conv.py:455\u001b[0m, in \u001b[0;36mConv2d._conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    451\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mzeros\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m    452\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mconv2d(F\u001b[38;5;241m.\u001b[39mpad(\u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reversed_padding_repeated_twice, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode),\n\u001b[1;32m    453\u001b[0m                     weight, bias, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstride,\n\u001b[1;32m    454\u001b[0m                     _pair(\u001b[38;5;241m0\u001b[39m), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdilation, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgroups)\n\u001b[0;32m--> 455\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv2d\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstride\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    456\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpadding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdilation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgroups\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# for model in \n",
    "# accuracy_list, precision_list, recall_list, f1_list, tps, tns, fps, fns = train_net(\"googlenet\")\n",
    "model_names = [\n",
    "    # \"resnet50\",\n",
    "    # \"resnet18\", \n",
    "    # \"alexnet\", \n",
    "    # \"vgg16\",\n",
    "    \"densenet\", \n",
    "    # \"inception\", \n",
    "    # \"googlenet\", \n",
    "    # \"resnext50_32x4d\", \n",
    "    # \"wide_resnet50_2\"\n",
    "]\n",
    "test_ratio=0.3\n",
    "acc_map = {}\n",
    "pre_map = {}\n",
    "rec_map = {}\n",
    "f1_map = {}\n",
    "tps_map = {}\n",
    "tns_map = {}\n",
    "fps_map = {}\n",
    "fns_map = {}\n",
    "mis_total_map = {}\n",
    "for model_name in model_names:\n",
    "    print(f\"training {model_name}...\")\n",
    "    current_date = datetime.now().strftime('%Y-%m-%d')\n",
    "    os.makedirs(f\"./output/tl+rotation/{current_date}/{model_name}\", exist_ok=True)\n",
    "    show_ = False\n",
    "    accuracy_list, precision_list, recall_list, f1_list, tps, tns, fps, fns, confusion_matrix_list = train_net(model_name)\n",
    "    plot_metric(accuracy_list, 'Accuracy', model=model_name, save=True, show=show_, output=f\"output/tl+rotation/{current_date}\", num_epochs=num_epochs, test_ratio=test_ratio)\n",
    "    plot_metric(precision_list, 'Precision', model=model_name, save=True, show=show_,output=f\"output/tl+rotation/{current_date}\", num_epochs=num_epochs, test_ratio=test_ratio)\n",
    "    plot_metric(recall_list, 'Recall', model=model_name, save=True, show=show_,output=f\"output/tl+rotation/{current_date}\", num_epochs=num_epochs, test_ratio=test_ratio)\n",
    "    plot_metric(f1_list, 'F1 Score', model=model_name, save=True, show=show_,output=f\"output/tl+rotation/{current_date}\", num_epochs=num_epochs, test_ratio=test_ratio)\n",
    "    for time in [1, 20, 40, 60, 80, 100, 120, 140, 160, 180, 200, 220, 240, 260, 280, 289]:\n",
    "    # for time in [1]:\n",
    "        plot_confusion_matrix(confusion_matrix_list, time, save=True, show=show_,output=f\"./output/tl+rotation/{current_date}/{model_name}\")\n",
    "    # acc_map[model_name] = accuracy_list\n",
    "    # pre_map[model_name] = precision_list\n",
    "    # rec_map[model_name] = recall_list\n",
    "    # f1_map[model_name] = f1_list\n",
    "    # tps_map[model_name] = tps\n",
    "    # tns_map[model_name] = tns\n",
    "    # fps_map[model_name] = fps\n",
    "    # fns_map[model_name] = fns\n",
    "\n",
    "    print(f\"{model_name} average accuracy:\", sum(accuracy_list) / len(accuracy_list))\n",
    "\n",
    "    mis_map = write_result(model_name, accuracy_list, precision_list, recall_list, f1_list, tps, tns, fps, fns, confusion_matrix_list)\n",
    "    if not mis_total_map:\n",
    "        mis_total_map = mis_map\n",
    "    else:\n",
    "        mis_total_map  = add_dicts(mis_total_map, mis_map)\n",
    "    # print(f\"{model_name} misclassified map: {mis_map}\")\n",
    "    print(f\"total map: {mis_total_map}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32a4408e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for timestamp in range(1, 2):\n",
    "# # for timestamp in range(1, 10):\n",
    "#     print(\"timestamp: \", timestamp)\n",
    "#     dataloaders = get_dataloaders(timestamp, data_enrich=True)\n",
    "\n",
    "#     print(len(dataloaders['train'].dataset))\n",
    "#     print(len(dataloaders['val'].dataset))\n",
    "#     print(len(dataloaders['test'].dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e867a91d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
